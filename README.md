# Week-12-Lecture
Week-12-Lecture

### 역전파는 어떻게 AI의 암흑기를 끝내고 딥러닝의 시작을 열었는가?
* 논문명: Learning representations by back-propagating errors”(Rumelhart, Hinton, Williams, 1986)

### 논문배경
* 당시 신경망은 입력과 출력만 연결한 구조에서만 학습이 가능했다.
    * ‘정답만 맞추는 연습’은 할 수 있었지만, ‘생각하는 과정’을 배우는 기능은 없었습니다.
* Hidden Layer가 추가되면 그 내부를 학습시키는 방법이 없었다.
    * 옛 신경망은 ‘정답’은 가르칠 수 있었지만, ‘생각 과정’을 어떻게 고쳐야 할지 알려줄 방법이 없었습니다.
* 기존 학습 규칙(예: 퍼셉트론)은 입력–출력 연결 강도만 조정할 수 있었다.
* 이로 인해 모델이 스스로 중간 개념을 배우는 표현 학습이 불가능했다.
* 본 논문은 Hidden Layer까지 학습 가능한 새로운 학습법 제안을 목표로 출발했다.

### 기존 연구의 한계점
* 당시 신경망은 ‘답만 외우는 학생’과 같아서, 생각하는 과정과 개념 만들기는 불가능했다.
* 중간에 어떤 생각 과정을 거쳤는지 확인할 수 없었다.
* 복잡한 문제를 단순 기준으로만 해결하려 했다.
* 스스로 새로운 아이디어나 특징을 만들지 못했다. 즉 사람이 알려주지 않으면 특징을 발견하지 못했다.

### 논문 목표
* Hidden Layer가 스스로 표현을 구축하도록 하는 학습 방법을 만드는 것이 목표다.
* 단순하면서도 다양한 다층 신경망에 적용 가능한 일반적 알고리즘을 제시하는 것이 목표다.

### 논문내용(주요 혁신 및 방법론)
* VAE의 해결책: "인코더와 디코더의 협동 작전"
   * VAE는 이 문제를 해결하기 위해 두 명의 기술자를 고용했습니다. 
* 인코더 (Encoder): "요약의 달인"
   * 역할: 복잡한 사진(데이터)을 보고 핵심 특징(설계도 z)을 추측합니다.
   * 하는 일: "이 사진은 뾰족 귀 80%, 흰 털 20%의 특징을 가졌어!"라고 평균(u)과 범위(시그마)를 요약해줍니다.
* 디코더 (Decoder): "재현의 달인"
   * 역할: 인코더가 준 설계도를 보고 다시 원본 사진을 그려냅니다.
   * 하는 일: "그 특징이라면... 이런 그림이 나오겠군!" 하고 그림을 만들어냅니다.
* 학습 방법
   * 입력: 고양이 사진을 넣음
   * 압축: 인코더가 설계도(특징)를 추출
   * 복원: 디코더가 다시 그림을 그림
   * 비교: 원본 사진과 얼마나 다른지 비교해서 오차를 줄여나감
*  ✨핵심 마법: Reparameterization Trick (재매개변수화 트릭) ✨
   * VAE가 학습 가능해지도록 만든 핵심 아이디어로,
   * 중간에 무작위로 샘플링하는 과정 때문에 발생하는 ‘미분 불가능’ 문제를 해결한다.
        * AI는 결과가 틀렸을 때 어디를 얼마나 고칠지 계산하는데, 이 계산이 바로 미분입니다.
        * 그런데 중간에 랜덤 샘플링이 들어가면 결과가 우연으로 결정되어 어떤 값이 영향을 줬는지 추적할 수 없습니다.
        *  마치 주사위를 굴려 3이 나왔을 때 “다음엔 4가 나오게 주사위를 어떻게 깎아야 하지?”라고 질문하는 것과 같습니다.
        *  즉, 랜덤은 원인과 결과의 연결을 끊어버리기 때문에 미분이 불가능합니다.
        *  그래서 AI는 “뭘 어떻게 고쳐야 하는지” 알 수 없어 학습이 멈춰버리게 됩니다.
   * 원래는 모델이 직접 랜덤 값을 뽑기 때문에 오류를 어디서 수정해야 할지 계산할 수 없었지만,
   * 무작위 과정을 “고정된 평균과 분산에 AI가 추가로 조절하는 노이즈를 더하는 방식”으로 바꾸며 이 문제가 해결된다.
   *  즉 무작위 뽑기 = 평균(μ) + 분산(σ) × 노이즈(ε) 형태로 재구성하여,
   *  랜덤 요소는 외부에서 제공하고 모델은 평균과 분산만 조절하도록 바뀐다.
   *  <img width="445" height="215" alt="image" src="https://github.com/user-attachments/assets/aa3ce0d4-01b6-4836-977c-dbd0a30e3e22" />
   * 일상비유
   <img width="943" height="537" alt="image" src="https://github.com/user-attachments/assets/b1c8095e-39e2-4b20-bd04-bcf525514547" />


   *  그 결과 모델은 출력이 잘못되면 평균이나 분산 값을 미분을 통해 조정할 수 있게 되어 학습이 가능해진다.
   *  이 트릭 덕분에 VAE는 확률적 생성 과정을 포함하면서도 역전파가 가능해졌고,
   *  생성형 AI 구조의 기반이 될 수 있었다.

### 기여도 및 결과
* VAE 덕분에 AI는 단순히 있는 것을 분류하는 것을 넘어, 없는 것을 만들어내는(Generative) 능력을 갖게 되었습니다.
* 새로운 창작: 세상에 없는 사람 얼굴, 본 적 없는 풍경을 그려냅니다.
* 보간 (Interpolation): 웃는 얼굴과 우는 얼굴 사이의 **'중간 표정'**을 자연스럽게 만들어냅니다. (설계도 상에서 부드럽게 이동)
* 복원: 노이즈가 낀 사진을 보고 깨끗한 원본 설계도를 추측해 복구합니다.


### 참고 파일

* 논문1. Auto-Encoding Variational Bayes
